<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Support Vector Machines and Constrained Optimization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../eve.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="shortcut icon" href="../eve.ico">
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GZHXTPTRRE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GZHXTPTRRE');
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Fall 2025</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <span class="nav-link">
<span class="menu-text">Canvas</span>
    </span>
  </li>  
  <li class="nav-item">
    <span class="nav-link">
<span class="menu-text">Gradescope</span>
    </span>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#support-vector-machines" id="toc-support-vector-machines" class="nav-link active" data-scroll-target="#support-vector-machines">Support Vector Machines</a></li>
  <li><a href="#computing-the-margin" id="toc-computing-the-margin" class="nav-link" data-scroll-target="#computing-the-margin">Computing the Margin</a></li>
  <li><a href="#constrained-optimization" id="toc-constrained-optimization" class="nav-link" data-scroll-target="#constrained-optimization">Constrained Optimization</a></li>
  <li><a href="#the-dual-problem" id="toc-the-dual-problem" class="nav-link" data-scroll-target="#the-dual-problem">The Dual Problem</a></li>
  <li><a href="#kernel-trick" id="toc-kernel-trick" class="nav-link" data-scroll-target="#kernel-trick">Kernel Trick</a></li>
  <li><a href="#soft-margin" id="toc-soft-margin" class="nav-link" data-scroll-target="#soft-margin">Soft Margin</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>Support Vector Machines and Constrained Optimization</strong></h1>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<p>We have so far explored the Naive Bayes classifier and logistic regression for solving classification tasks. In this section, we will learn about another tool called support vector machines (SVMs). While the final algorithm will be similar to logistic regression, SVMs approach the problem from a different perspective. As we’ll soon discover, both logistic regression and SVMs have their own strengths and weaknesses. Plus, we’ll get to see some fun math along the way!</p>
<section id="support-vector-machines" class="level3">
<h3 class="anchored" data-anchor-id="support-vector-machines">Support Vector Machines</h3>
<p>Consider a binary classification problem with data points <span class="math inline">\(\mathbf{x}^{(i)}\)</span> and labels <span class="math inline">\(y^{(i)} \in \{-1, 1\}\)</span>. (We previously used <span class="math inline">\(y^{(i)} \in \{0, 1\}\)</span>, but this is just a relabeling for convenience.) We want to find a hyperplane that separates the two classes. For the majority of our discussion, we will assume that the data is linearly separable, meaning there exists a hyperplane that can perfectly separate the two classes.</p>
<center>
<img src="images/svm_data.pdf" class="responsive-img">
</center>
<p>When there is such a separating hyperplane, there are often infinitely many that we can choose from. The question at the heart of support vector machines is: which hyperplane should we choose?</p>
<center>
<img src="images/svm_possible_lines.pdf" class="responsive-img">
</center>
<p>As we’ve seen in the past, it is not too difficult to find a model that perfectly fits our training data; the real challenge is to find a model that generalizes well to unseen data. In the context of classification, we may expect that a model that separates the two classes with the largest ‘margin of error’ will generalize better than one that is very close to the data points. With this in mind, Vladimir Vapnik and Alexey Chervonenkis proposed the idea of support vector machines, which aim to find the hyperplane that maximizes the margin between the two classes.</p>
<center>
<img src="images/svm_definition.pdf" class="responsive-img">
</center>
<p>Let’s consider a particular hyperplane, defined by the normal vector <span class="math inline">\(\mathbf{w}\)</span> and bias <span class="math inline">\(b\)</span>. The equation of the hyperplane is given by: <span class="math display">\[
\begin{align}
\langle \mathbf{w}, \mathbf{x} \rangle - b = 0.
\end{align}
\]</span></p>
<p>We will define <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span> so that <span class="math inline">\(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b \geq 1\)</span> for all points <span class="math inline">\(\mathbf{x}^{(i)}\)</span> in the positive class (<span class="math inline">\(y^{(i)} = 1\)</span>) and <span class="math inline">\(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b \leq -1\)</span> for all points in the negative class (<span class="math inline">\(y^{(i)} = -1\)</span>). As we can see in the figure above, such a hyperplane will always exist if the data is linearly separable. How can we find the hyperplane that maximizes the margin?</p>
</section>
<section id="computing-the-margin" class="level3">
<h3 class="anchored" data-anchor-id="computing-the-margin">Computing the Margin</h3>
<p>For a given <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>, we can see that the margin is the distance between the hyperplane <span class="math inline">\(\langle \mathbf{w}, \mathbf{x} \rangle - b = 1\)</span> and the hyperplane <span class="math inline">\(\langle \mathbf{w}, \mathbf{x} \rangle - b = -1\)</span>. Let’s calculate this distance.</p>
<center>
<img src="images/svm_margin.pdf" class="responsive-img">
</center>
<p>Consider a point <span class="math inline">\(\mathbf{z}_1\)</span> on the hyperplane <span class="math inline">\(\langle \mathbf{w}, \mathbf{x} \rangle - b = 1\)</span>. Let <span class="math inline">\(\mathbf{z}_2\)</span> be the point on the hyperplane <span class="math inline">\(\langle \mathbf{w}, \mathbf{x} \rangle - b = -1\)</span> that is <em>closest</em> to <span class="math inline">\(\mathbf{z}_1\)</span>. Because <span class="math inline">\(\mathbf{z}_1\)</span> and <span class="math inline">\(\mathbf{z}_2\)</span> are the closest points to each other on the two hyperplanes, the line connecting them is perpendicular to both hyperplanes. (Otherwise, we could move along the hyperplane <span class="math inline">\(\langle \mathbf{w}, \mathbf{x} \rangle - b = -1\)</span> to find a point <span class="math inline">\(\mathbf{z}_2'\)</span> that is closer to <span class="math inline">\(\mathbf{z}_1\)</span> than <span class="math inline">\(\mathbf{z}_2\)</span>, contradicting our assumption that <span class="math inline">\(\mathbf{z}_2\)</span> is the closest point.) Formally, we can write: <span class="math display">\[
\mathbf{z}_1 - \mathbf{z}_2 = \lambda \bar{\mathbf{w}}
\]</span> for some scaling <span class="math inline">\(\lambda \in \mathbb{R}\)</span>, where <span class="math inline">\(\bar{\mathbf{w}}\)</span> is the unit normal vector <span class="math inline">\(\frac{\mathbf{w}}{\|\mathbf{w}\|_2}\)</span>. We are interested in the length of this vector <span class="math inline">\(\lambda\)</span>. By our observation above, we can write <span class="math inline">\(\mathbf{z}_1 =  \lambda \bar{\mathbf{w}} + \mathbf{z}_2\)</span>. Then, plugging in <span class="math inline">\(\mathbf{z}_1\)</span> into the hyperplane equation <span class="math inline">\(\langle \mathbf{w}, \mathbf{z}_1 \rangle - b = 1\)</span>, we have: <span class="math display">\[
\begin{align}
1 &amp;= \langle \mathbf{w}, \lambda \bar{\mathbf{w}} + \mathbf{z}_2 \rangle - b
\\ &amp;= \langle \mathbf{w}, \lambda \bar{\mathbf{w}} \rangle + \langle \mathbf{w}, \mathbf{z}_2 \rangle - b
\\ &amp;= \lambda \langle \mathbf{w}, \bar{\mathbf{w}} \rangle - 1
\\ &amp;= \frac{\lambda}{\| \mathbf{w} \|_2} \| \mathbf{w} \|_2^2 - 1.
\end{align}
\]</span> Rearranging, we have that <span class="math inline">\(\lambda = \frac2{\| \mathbf{w} \|_2}\)</span>. For a given <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>, we now know how to compute the margin. Let’s now find the <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span> with the largest margin.</p>
</section>
<section id="constrained-optimization" class="level3">
<h3 class="anchored" data-anchor-id="constrained-optimization">Constrained Optimization</h3>
<p>We can formalize our goal as a constrained optimization problem: We want to find the hyperplane that maximizes the margin, subject to the constraints that all points in the positive class are on one side of the hyperplane and all points in the negative class are on the other side.</p>
<p>Observe that maximizing the margin is equivalent to minimizing the <em>inverse</em> of the margin, which, by our calculation above, is equivalent to minimizing <span class="math inline">\(\frac12 \| \mathbf{w} \|_2\)</span>. Further, notice that we can simplify our constraints: <span class="math inline">\(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b \geq 1 \text{ for } y^{(i)} = 1\)</span> and <span class="math inline">\(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b \leq -1 \text{ for } y^{(i)} = -1\)</span> is equivalent to $ y^{(i)}(, ^{(i)} - b) $ for all <span class="math inline">\(i\)</span>. (This is why we relabelled the classes so that <span class="math inline">\(y^{(i)} \in \{-1, 1\}\)</span>.) We can now write our optimization problem as follows: <span class="math display">\[
\begin{align}
\min_{\mathbf{w}, b} \frac12 \| \mathbf{w} \|_2^2 \textnormal{ such that }
y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b) \geq 1 \text{ } \forall i.
\end{align}
\]</span></p>
<p>The points <span class="math inline">\(\mathbf{x}^{(i)}\)</span> that lie on the hyperplane i.e., those for which <span class="math inline">\(y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b) = 1\)</span> are called the <em>support vectors</em>. Let <span class="math inline">\(\mathcal{S}\)</span> be the set of indices of the support vectors.</p>
<center>
<img src="images/svm_supports.pdf" class="responsive-img">
</center>
<p>The problem above is known as an example of a <em>constrained optimization problem</em>. More specifically, it is a <em>quadratic programming</em> problem: we have a quadratic objective function (the term <span class="math inline">\(\frac12 \| \mathbf{w} \|_2^2\)</span> is quadratic in <span class="math inline">\(\mathbf{w}\)</span>) and linear constraints (the constraints are linear in <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>). Constrained optimization problems in general, and quadratic programming in particular, are a rich area of study in optimization, and there are many techniques to solve them. However, the time complexity of these techniques will depend on the number of variables in <span class="math inline">\(\mathbf{w}\)</span>. For data in high dimensions (e.g., the transformed data after we add features to make the classes linearly separable), the time complexity can be quite high. In the next section, we will see how to find the <em>dual</em> of this problem, which can allow us to solve it more efficiently.</p>
<p>Before we do, let’s see why the hyperplane is called a <em>support vector machine</em>.</p>
<p><strong>Claim</strong>: The optimal hyperplane <span class="math inline">\(\mathbf{w}^\star\)</span> is a linear combination of the support vectors: <span class="math display">\[
\mathbf{w}^\star = \sum_{i \in \mathcal{S}} \beta_i  y^{(i)} \mathbf{x}^{(i)}
\]</span> for some coefficients <span class="math inline">\(\beta_i \in \mathbb{R}\)</span>.</p>
<p><strong>Proof</strong>: Suppose for contradiction that <span class="math inline">\(\mathbf{w}^\star\)</span> is not a linear combination of the support vectors. That is, <span class="math inline">\(\mathbf{w}^\star = \sum_{i \in \mathcal{S}} \beta_i  y^{(i)} \mathbf{x}^{(i)} + \mathbf{v}\)</span> for some vector <span class="math inline">\(\mathbf{v}\)</span> that is orthogonal to all support vectors. We will construct a new hyperplane <span class="math inline">\(\mathbf{w}' = \mathbf{w}^\star - \epsilon \mathbf{v}\)</span> for some small <span class="math inline">\(\epsilon &gt; 0\)</span>, so that each point is still correctly classified, and the margin is larger than that of <span class="math inline">\(\mathbf{w}^\star\)</span>.</p>
<p>Let’s check that the new hyperplane <span class="math inline">\(\mathbf{w}'\)</span> still correctly classifies all points. First, for any support vector <span class="math inline">\(\mathbf{x}^{(i)}\)</span>, we have <span class="math display">\[
\langle \mathbf{w}', \mathbf{x}^{(i)} \rangle = \langle \mathbf{w}^\star - \epsilon \mathbf{v}, \mathbf{x}^{(i)} \rangle = \langle \mathbf{w}^\star, \mathbf{x}^{(i)} \rangle
\]</span> since <span class="math inline">\(\mathbf{v}\)</span> is orthogonal to all support vectors. By assumption, <span class="math inline">\(\mathbf{w}^\star\)</span> satisfies <span class="math inline">\(y^{(i)}(\langle \mathbf{w}^\star, \mathbf{x}^{(i)} \rangle - b) = 1\)</span>. Second, for any non-support vector <span class="math inline">\(\mathbf{x}^{(j)}\)</span>, we have <span class="math display">\[
\langle \mathbf{w}', \mathbf{x}^{(j)} \rangle = \langle \mathbf{w}^\star - \epsilon \mathbf{v}, \mathbf{x}^{(j)} \rangle = \langle \mathbf{w}^\star, \mathbf{x}^{(j)} \rangle - \epsilon \langle \mathbf{v}, \mathbf{x}^{(j)} \rangle.
\]</span> Since <span class="math inline">\(\mathbf{x}^{(j)}\)</span> is not a support vector, we have <span class="math inline">\(y^{(j)} (\langle \mathbf{v}, \mathbf{x}^{(j)} \rangle - b) &gt; 1\)</span>. Because this inequality is strict, we can choose <span class="math inline">\(\epsilon\)</span> small enough so that <span class="math inline">\(y^{(j)}(\langle \mathbf{w}', \mathbf{x}^{(j)} \rangle - b) = y^{(j)}(\langle \mathbf{w}^\star, \mathbf{x}^{(j)} \rangle - b - \epsilon \langle \mathbf{v}, \mathbf{x}^{(j)} \rangle) &gt; 1\)</span>.</p>
<p>Next, let’s check that the margin of <span class="math inline">\(\mathbf{w}'\)</span> is larger than that of <span class="math inline">\(\mathbf{w}^\star\)</span>. Since <span class="math inline">\(\mathbf{v}\)</span> is orthogonal to all support vectors, we can write: <span class="math display">\[
\begin{align}
\| \mathbf{w}' \|_2^2
&amp;= \| \sum_{i \in \mathcal{S}} \beta_i y^{(i)} \mathbf{x}^{(i)} - (1-\epsilon) \mathbf{v} \|_2^2 \\
&amp;= \| \sum_{i \in \mathcal{S}} \beta_i y^{(i)} \mathbf{x}^{(i)} \|_2^2 + (1-\epsilon)^2 \| \mathbf{v} \|_2^2 \\
&amp;&lt; \| \sum_{i \in \mathcal{S}} \beta_i y^{(i)} \mathbf{x}^{(i)} \|_2^2 + \| \mathbf{v} \|_2^2 = \| \mathbf{w}^\star \|_2^2.
\end{align}
\]</span> Since the length of the normal vector <span class="math inline">\(\mathbf{w}\)</span> is inversely proportional to the margin, we have that the margin of <span class="math inline">\(\mathbf{w}'\)</span> is larger than that of <span class="math inline">\(\mathbf{w}^\star\)</span>, a contradiction!</p>
</section>
<section id="the-dual-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-dual-problem">The Dual Problem</h3>
<p>We have derived a quadratic programming problem, which we’ll call the <em>primal problem</em>:</p>
<p><span class="math display">\[
\begin{align}
\min_{\mathbf{w}, b} \frac12 \| \mathbf{w} \|_2^2 \textnormal{ such that }
y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b) \geq 1 \text{ } \forall i \in \mathcal{S}.
\end{align}
\]</span></p>
<p>In the version above, we only include the constraints for the support vectors <span class="math inline">\(\mathcal{S}\)</span>. Notice that this is sufficient because the remaining points are correctly classified by the hyperplane defined by the support vectors.</p>
<p>The challenge in directly solving the primal is that the number of variables in <span class="math inline">\(\mathbf{w}\)</span> is equal to the number of features, which can be very large especially if we apply feature transformations to the data. Fortunately, we can turn the <em>primal</em> into a <em>dual problem</em>, that, roughly speaking, converts each constraint into a variable, and each variable into a constraint. Notice that this is particularly useful because we only need the constraints for the support vectors, which could be much fewer than the total number of data points <span class="math inline">\(n\)</span>.</p>
<p>Let’s begin with the <em>Lagrangian</em> of the primal problem: <span class="math display">\[
\begin{align}
\min_{\mathbf{w}, b} \max_{\boldsymbol{\alpha}} \frac12 \| \mathbf{w} \|_2^2 - \sum_{i \in \mathcal{S}} \alpha_i \left( y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b) - 1 \right)
= \min_{\mathbf{w}, b} \max_{\boldsymbol{\alpha}} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}),
\end{align}
\]</span> where <span class="math inline">\(\boldsymbol{\alpha} \in \mathbb{R}^{|\mathcal{S}|}_+\)</span> is a vector of non-negative real numbers. Let’s see why the Lagrangian is equivalent to the primal problem: For a particular <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>, the constraints in the primal problem must be satisfied by the Lagrangian, otherwise there is some <span class="math inline">\(i\)</span> such that <span class="math inline">\(y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b) &lt; 1\)</span> and we can arbitrarily increase the Lagrangian objective by increasing <span class="math inline">\(\alpha_i\)</span>. Among these <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span> that satisfy the constraints, the Lagrangian objective is minimized when <span class="math inline">\(\frac12 \|\mathbf{w}\|_2^2\)</span> is as small as possible, which is equivalent to minimizing the objective of the primal problem.</p>
<p>The Lagrangian is useful because we can more easily reason about the optimal <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>. Notice that the Lagrangian is a <em>convex</em> function in <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>, and a <em>concave</em> function in <span class="math inline">\(\boldsymbol{\alpha}\)</span>. Further, as long as the data is linearly separable, we can always come up with a <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span> such that the constraints are satisfied, namely with <span class="math inline">\(\boldsymbol{\alpha} = 0\)</span>. Together, by <a href="https://en.wikipedia.org/wiki/Slater%27s_condition">Slater’s condition</a>, we can apply the <a href="https://en.wikipedia.org/wiki/Minimax_theorem">minimax theorem</a> to exchange the order of the minimization and maximization. That is, <span class="math display">\[
\min_{\mathbf{w}, b} \max_{\boldsymbol{\alpha}} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha})
= \max_{\boldsymbol{\alpha}} \min_{\mathbf{w}, b} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}).
\]</span></p>
<p>Let’s fix a <span class="math inline">\(\boldsymbol{\alpha}\)</span> and minimize the Lagrangian with respect to <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>. Taking the gradient with respect to <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(b\)</span>, and setting it to zero, we have: <span class="math display">\[
\begin{align}
\nabla_{\mathbf{w}} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha})
&amp;= \mathbf{w} - \sum_{i \in \mathcal{S}} \alpha_i y^{(i)} \mathbf{x}^{(i)} = 0
\\\nabla_{b} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha})
&amp;= \sum_{i \in \mathcal{S}} \alpha_i y^{(i)} = 0.
\end{align}
\]</span> Then we have <span class="math inline">\(\mathbf{w} = \sum_{i \in \mathcal{S}} \alpha_i y^{(i)} \mathbf{x}^{(i)}\)</span>. Notice that this implies the claim we made earlier: the optimal hyperplane <span class="math inline">\(\mathbf{w}^\star\)</span> is a linear combination of the support vectors, with coefficients <span class="math inline">\(\alpha_i y^{(i)}\)</span>. Further, we have that <span class="math inline">\(\sum_{i \in \mathcal{S}} \alpha_i y^{(i)} = 0\)</span>. We can plug these two equations into the Lagrangian to obtain <span class="math display">\[
\begin{align}
\mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha})
&amp;=
\frac12 \left( \sum_{i \in \mathcal{S}} \alpha_i y^{(i)} \mathbf{x}^{(i)} \right)^2
- \sum_{i \in \mathcal{S}} \alpha_i y^{(i)} {\mathbf{x}^{(i)}}^\top \sum_{j \in \mathcal{S}} \alpha_j y^{(j)} \mathbf{x}^{(j)}
+ b \sum_{i \in \mathcal{S}} \alpha_i y^{(i)}
+ \sum_{i \in \mathcal{S}} \alpha_i
\\&amp;=
- \frac12 \sum_{i, j \in \mathcal{S}} \alpha_i \alpha_j y^{(i)} y^{(j)} \langle \mathbf{x}^{(i)}, \mathbf{x}^{(j)} \rangle
+ \sum_{i \in \mathcal{S}} \alpha_i.
\end{align}
\]</span> Finally, the dual problem is given by <span class="math display">\[
\begin{align}
\max_{\boldsymbol{\alpha}} \sum_{i \in \mathcal{S}} \alpha_i - \frac12 \sum_{i, j \in \mathcal{S}} \alpha_i \alpha_j y^{(i)} y^{(j)} \langle \mathbf{x}^{(i)}, \mathbf{x}^{(j)} \rangle
\text{ such that } \alpha_i \geq 0 \text{ and } \sum_{i \in \mathcal{S}} \alpha_i y^{(i)} = 0.
\end{align}
\]</span></p>
</section>
<section id="kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="kernel-trick">Kernel Trick</h3>
<p>We have framed support vector machines as a tool that requires linearly separable data. However, we often need to apply a transformation <span class="math inline">\(\psi: \mathbb{R}^d \to \mathbb{R}^D\)</span> to the data to make it linearly separable. For most kernels, <span class="math inline">\(D\)</span> is very large, and explicitly computing the transformation <span class="math inline">\(\psi(\mathbf{x}^{(i)})\)</span> is infeasible. Fortunately, we can use the <em>kernel trick</em> to compute the inner product without explicitly computing the transformation. The kernel trick allows us to define a kernel function <span class="math inline">\(K: \mathbb{R^d} \times \mathbb{R}^d \to \mathbb{R}\)</span> such that <span class="math display">\[
\begin{align}
K(\mathbf{x}^{(i)}, \mathbf{x}^{(j)}) = \langle \psi(\mathbf{x}^{(i)}), \psi(\mathbf{x}^{(j)}) \rangle.
\end{align}
\]</span></p>
<p>For many years, I was confused about why the kernel trick works. Doesn’t computing the inner product require us to apply the transformation <span class="math inline">\(\psi\)</span>?</p>
<p>Let’s see two examples:</p>
<p><strong>Polynomial Kernel</strong>: Consider the polynomial kernel <span class="math inline">\(K(\mathbf{x}, \mathbf{x}') = (\langle \mathbf{x}, \mathbf{x}' \rangle + 1)^p\)</span> for <span class="math inline">\(p \in \mathbb{N}\)</span>. The explicit transformation <span class="math inline">\(\psi\)</span> when <span class="math inline">\(p=2\)</span> and <span class="math inline">\(d=3\)</span> is given by: <span class="math display">\[
\psi(\mathbf{x}) = \begin{bmatrix}
1 \\
\sqrt{2} x_1 \\
\sqrt{2} x_2 \\
\sqrt{2} x_3 \\
x_1^2 \\
x_2^2 \\
x_3^2 \\
\sqrt{2} x_1 x_2 \\
\sqrt{2} x_1 x_3 \\
\sqrt{2} x_2 x_3 \\
\end{bmatrix}
\]</span> However, we can efficiently compute the inner product without explicitly computing <span class="math inline">\(\psi\)</span>. For example, <span class="math display">\[
\begin{align}
K(\mathbf{x}, \mathbf{w}) &amp;= (\langle \mathbf{x}, \mathbf{w} \rangle + 1)^2
\\&amp;= (1 + x_1 x_1' + x_2 x_2' + x_3 x_3')^2
\\&amp;= 1 + 2x_1 x_1' + 2x_2 x_2' + 2x_3 x_3' + x_1^2 x_1'^2 + x_2^2 x_2'^2
\\+&amp; x_3^2 x_3'^2 + 2x_1 x_2 x_1' x_2' + 2x_1 x_3 x_1' x_3' + 2x_2 x_3 x_2' x_3'
\\&amp;= \langle \psi(\mathbf{x}), \psi(\mathbf{x}') \rangle.
\end{align}
\]</span></p>
<p><strong>Gaussian Kernel</strong>: Consider the Gaussian kernel <span class="math inline">\(K(\mathbf{x}, \mathbf{x}') = e^{-\frac{\|\mathbf{x} - \mathbf{x}'\|_2^2}{2\sigma^2}}\)</span> for some <span class="math inline">\(\sigma &gt; 0\)</span>. As shown <a href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">here</a>, the Gaussian kernel can be expressed as an infinite series. Instead of explicitly computing the transformation <span class="math inline">\(\psi\)</span>, we can compute the kernel in <span class="math inline">\(O(d)\)</span> time by computing the inner product <span class="math inline">\(\langle \mathbf{x}, \mathbf{x}' \rangle\)</span>, and then applying the exponential function with a scaling.</p>
</section>
<section id="soft-margin" class="level3">
<h3 class="anchored" data-anchor-id="soft-margin">Soft Margin</h3>
<p>We have so far assumed that the data is linearly separable. However, in practice, we may have noisy data or outliers that make it impossible to find a hyperplane that perfectly separates the two classes. To address this, we can modify our optimization problem to allow for some misclassification. We can do this by introducing slack variables <span class="math inline">\(\xi_i \geq 0\)</span> for each data point, which allow us to ‘relax’ the constraints. The modified optimization problem is given by:</p>
<p><span class="math display">\[
\begin{align}
\min_{\mathbf{w}, b} \| \mathbf{w} \|^2 + C \sum_{i=1}^n \xi_i
\text{ such that }
y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b) \geq 1 - \xi_i \text{ and } \xi_i \geq 0 \text{ for all } i.
\end{align}
\]</span></p>
<center>
<img src="images/svm_soft.pdf" class="responsive-img">
</center>
<p>The optimal choice of each slack variable satisfies <span class="math inline">\(\xi_i = \max(0, 1 - y^{(i)}(\langle \mathbf{w}, \mathbf{x}^{(i)} \rangle - b))\)</span>. The parameter <span class="math inline">\(C &gt; 0\)</span> controls the trade-off between maximizing the margin and minimizing the misclassification. Notice that this is equivalent to minimizing the hinge loss, with a <span class="math inline">\(\ell_2\)</span> regularization term.</p>
<center>
<img src="images/svm_loss.pdf" class="responsive-img">
</center>



</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const wordsPerMinute = 200;
  const text = document.body.innerText;
  const words = text.trim().split(/\s+/).length;
  const readingTime = Math.ceil(words / wordsPerMinute);

  const readTimeEl = document.createElement("div");
  readTimeEl.innerText = `⏱️ ${readingTime} min read`;

  // Style it to appear centered
  readTimeEl.style.fontSize = "0.9em";
  readTimeEl.style.margin = "1em auto";
  readTimeEl.style.textAlign = "left";
  readTimeEl.style.width = "100%";

  const title = document.querySelector("h1");
  if (title) {
    title.parentNode.insertBefore(readTimeEl, title.nextSibling);
  }
});
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>