---
title: "**CSCI 145: Data Mining**"
output:
  html_document:
    css: styles.css
---

<center>
*A course on the mathematical foundations of machine learning.*
</center>

<br>

<div class="row">
  <div class="col" markdown="1">

  **Instructor**: [R. Teal Witter](https://www.rtealwitter.com/). Please call me Teal.
  
  **Class Times**: We meet Tuesdays and Thursdays; Sec. 1 is scheduled from 2:45 to 4:00pm in Kravis 164, and Sec. 2 from 4:15 to 5:30pm in Kravis 165.
  
  **Office Hours**: Mondays and Wednesdays from 12:30 to 2pm in Adams 213.
  
  **Participation**: I expect you to engage in class, ask questions, and make connections. To receive credit, please fill out [this](https://forms.gle/zQG3iLAqCDTzDyv98) form after every lecture.

  **Problem Sets**: Your primary opportunity to learn the material will be on problem sets. You may work with others to solve the problems, but you must write your solutions by yourself, and explicitly acknowledge any outside help (websites, people, LLMs).

  </div>
  <div class="col" markdown="1">

  **Quizzes**:
  There will be short quizzes at the beginning of our Tuesday classes. These quizzes will test your understanding of the problem sets and the concepts from the prior week.

  **Exams**: The two exams are the primary method of assessing your understanding of the material. The first exam will cover the content from the first half of the course, while the second exam will cover the content from the second half.

  **Project**: The  project offers a chance to explore an area that interests you, practice writing high quality code, and develop your ability to communicate technical ideas to an audience. In addition to your codebase, you will write a report and give a short presentation at the end of the semester. 

  </div>
</div>

**Resources**: Most of the material we cover comes from either Chris Musco's phenomenal [machine learning course](https://www.chrismusco.com/machinelearning2024_grad/), or Chinmay Hegde's fantastic [deep learning course](https://chinmayhegde.github.io/dl-notes/). While we do not have a textbook, we do have typed notes; I **highly** recommend you read the notes before each class.

<table style="width: 100%; border-collapse: collapse;">
  <tr>
    <td>Week</td>
    <td>Tuesday</td>
    <td>Thursday</td>
    <td>Slides</td>
    <td>Assignments</td>
  </tr>

  <tr class="section-header">
    <td colspan="5">Warmup</td>
  </tr>
  <tr>
    <td>Week 1 (8/27 and 8/29)</td>
    <td><a href="notes/LinearAlgebra.qmd">Linear Algebra</a></td>
    <td><a href="notes/PageRank.qmd">PageRank</a></td>
    <td><a href="slides/Week1.pdf">Slides</a></td>
    <td>[Pset 1](psets/pset1.pdf) ([TeX](psets/pset1.tex)) due 9/22</td>
  </tr>

  <tr class="section-header">
    <td colspan="5">Supervised Learning</td>
  </tr>
  <tr>
    <td>Week 2 (9/2 and 9/4)</td>
    <td><a href="notes/LinearRegression.qmd">Linear Regression</a></td>
    <td><a href="notes/LinearRegression.qmd">Optimization</a></td>
    <td><a href="slides/Week2.pdf">Slides</a></td>
    <td>[Pset 2](psets/pset2.pdf) ([TeX](psets/pset2.tex)) due 9/8 </td>
  </tr>
  <tr>
    <td>Week 3 (9/9 and 9/11)</td>
    <td><a href="notes/GradientDescent.qmd">Gradient Descent</a></td>
    <td><a href="notes/PolynomialRegression.qmd">Polynomial Regression</a></td>
    <td><a href="slides/Week3.pdf">Slides</a></td>
    <td>[Pset 3](psets/pset3.pdf) ([TeX](psets/pset3.tex)) due 9/15 </td>
  </tr>
  <tr>
    <td>Week 4 (9/16 and 9/18)</td>
    <td><a href="notes/Probability.qmd">Probability</a></td>
    <td><a href="notes/LogisticRegression.qmd">Logistic Regression</a></td>
    <td><a href="slides/Week4.pdf">Slides</a></td>
    <td>[Pset 4](psets/pset4.pdf) ([TeX](psets/pset4.tex)) due 9/22 </td>
  </tr>
  <tr>
    <td>Week 5 (9/23 and 9/25)</td>
    <td><a href="notes/SupportVectorMachines.qmd">Support Vector Machines</a></td>
    <td><a href="notes/SupportVectorMachines.qmd">Constrained Optimization</a></td>
    <td></td>
    <td>[Pset 5](psets/pset5.pdf) ([TeX](psets/pset5.tex)) due 9/29 </td>
  </tr>
  <tr>
    <td>Week 6 (9/30 and 10/2)</td>
    <td><a href="notes/KernelMethods.qmd">Kernel Methods</a></td>
    <td><a href="notes/NeuralNetworks.qmd">Neural Networks</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 7 (10/7 and 10/9)</td>
    <td><a href="https://chinmayhegde.github.io/dl-notes/notes/lecture04/">Convolutional Networks</a></td>
    <td><a href="https://chinmayhegde.github.io/dl-notes/notes/lecture07/">Transformers</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 8 (10/14 and 10/16)</td>
    <td><i>Fall Break (No Class)</i></td>
    <td><a href="notes/DecisionTrees.qmd">Decision Trees</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 9 (10/21 and 10/23)</td>
    <td><i>Midterm Exam</i></td>
    <td><a href="notes/DecisionTrees.qmd">Boosting</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr class="section-header">
    <td colspan="5">Beyond Supervised Learning</td>
  </tr>
  <tr>
    <td>Week 10 (10/28 and 10/30)</td>
    <td><a href="notes/Autoencoders.qmd">Autoencoders</a></td>
    <td><a href="notes/Autoencoders.qmd">Principal Component Analysis</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 11 (11/4 and 11/6)</td>
    <td><a href="https://chinmayhegde.github.io/dl-notes/notes/lecture09/">Reinforcement Learning</a></td>
    <td><a href="https://chinmayhegde.github.io/dl-notes/notes/lecture10/">Q Learning</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 12 (11/11 and 11/13)</td>
    <td><a href="notes/Concentration.qmd">Concentration Inequalities</a></td>
    <td><a href="notes/Bandits.qmd">Multi-Armed Bandits</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 13 (11/18 and 11/20)</td>
    <td><a href="notes/ExplainableAI.qmd">Explainable AI</a></td>
    <td><a href="notes/ExplainableAI.qmd">Active Learning</a></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 14 (11/25 and 11/27)</td>
    <td><i>Midterm Exam</i></td>
    <td><i>Thanksgiving (No Class)</i></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 15 (12/2 and 12/4)</td>
    <td><i>Project Preparation</i></td>
    <td><i>Project Preparation (No Class)</i></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Week 16 (12/9 and 12/11)</td>
    <td><i>Sec. 2 Presents 7–10pm</i></td>
    <td><i>Sec. 1 Presents 2–5pm</i></td>
    <td></td>
    <td></td>
  </tr>
</table>
